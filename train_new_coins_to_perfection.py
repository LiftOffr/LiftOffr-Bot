#!/usr/bin/env python3
"""
New Coins Perfect Training Pipeline

This script trains the new trading pairs (AVAX/USD, MATIC/USD, UNI/USD, ATOM/USD)
using an advanced multi-stage approach to achieve:
1. 100% win rate
2. 100% prediction accuracy
3. 1000% returns

The pipeline implements:
- Sophisticated feature engineering
- Advanced deep learning architectures
- Hyperparameter optimization
- Ultra-precise ensemble methodology
- Dynamic parameter adaptation
- Multiple iterations with progressively higher accuracy targets
"""

import os
import sys
import json
import time
import logging
import argparse
import numpy as np
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional, Union

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("new_coins_perfect_training.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("train_new_coins_to_perfection")

# Constants
NEW_COINS = ["AVAX/USD", "MATIC/USD", "UNI/USD", "ATOM/USD"]
CONFIG_PATH = "config/new_coins_training_config.json"
DEFAULT_TIMEFRAMES = ["1h", "4h", "1d"]
OUTPUT_DIR = "training_output"
TARGET_ACCURACY = 0.99
TARGET_WIN_RATE = 0.99
TARGET_RETURN = 10.0  # 1000%

# Create necessary directories
Path(OUTPUT_DIR).mkdir(exist_ok=True)


def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description='Train new cryptocurrency pairs to achieve 100% accuracy and win rate.')
    parser.add_argument('--pairs', type=str, default=None,
                      help='Comma-separated list of pairs to train (default: all new coins)')
    parser.add_argument('--stages', type=int, default=3,
                      help='Number of training stages (default: 3)')
    parser.add_argument('--timeframes', type=str, default=None,
                      help='Comma-separated list of timeframes (default: 1h,4h,1d)')
    parser.add_argument('--skip-data-prep', action='store_true',
                      help='Skip data preparation if already done')
    parser.add_argument('--skip-hyperopt', action='store_true',
                      help='Skip hyperparameter optimization')
    parser.add_argument('--force', action='store_true',
                      help='Force regeneration of datasets and models')
    parser.add_argument('--target-accuracy', type=float, default=TARGET_ACCURACY,
                      help=f'Target accuracy (default: {TARGET_ACCURACY})')
    parser.add_argument('--target-win-rate', type=float, default=TARGET_WIN_RATE,
                      help=f'Target win rate (default: {TARGET_WIN_RATE})')
    parser.add_argument('--target-return', type=float, default=TARGET_RETURN,
                      help=f'Target return multiple (default: {TARGET_RETURN})')
    
    return parser.parse_args()


def load_config():
    """Load configuration from config file."""
    try:
        with open(CONFIG_PATH, 'r') as f:
            config = json.load(f)
        logger.info(f"Loaded configuration from {CONFIG_PATH}")
        return config
    except Exception as e:
        logger.error(f"Error loading configuration: {e}")
        return None


def run_command(cmd: List[str], description: str = None, capture_output: bool = True) -> Tuple[bool, str]:
    """
    Run a command and log its output.
    
    Args:
        cmd: Command to run
        description: Command description
        capture_output: Whether to capture output
        
    Returns:
        success: Whether the command succeeded
        output: Command output
    """
    if description:
        logger.info(f"Running: {description}")
    
    logger.info(f"Command: {' '.join(cmd)}")
    
    try:
        if capture_output:
            result = subprocess.run(
                cmd, 
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            output = result.stdout
            logger.info(f"Command completed successfully")
            return True, output
        else:
            result = subprocess.run(cmd, check=True)
            logger.info(f"Command completed successfully")
            return True, ""
    
    except subprocess.CalledProcessError as e:
        logger.error(f"Command failed with exit code {e.returncode}")
        if e.stderr:
            logger.error(f"Error output: {e.stderr}")
        return False, str(e)
    
    except Exception as e:
        logger.error(f"Error running command: {e}")
        return False, str(e)


def fetch_historical_data(pairs: List[str], timeframes: List[str] = None, 
                      days: int = 365, force: bool = False) -> bool:
    """
    Fetch historical data for all specified pairs and timeframes.
    
    Args:
        pairs: List of trading pairs
        timeframes: List of timeframes
        days: Number of days of historical data
        force: Whether to force data refresh
        
    Returns:
        success: Whether the operation succeeded
    """
    if timeframes is None:
        timeframes = DEFAULT_TIMEFRAMES
    
    timeframes_arg = ",".join(timeframes)
    pairs_arg = ",".join(pairs)
    
    cmd = [
        sys.executable, "fetch_historical_data.py",
        "--pairs", pairs_arg,
        "--timeframes", timeframes_arg,
        "--days", str(days)
    ]
    
    if force:
        cmd.append("--force")
    
    success, _ = run_command(
        cmd,
        f"Fetching historical data for {pairs_arg} across timeframes {timeframes_arg}",
        capture_output=True
    )
    
    return success


def prepare_advanced_training_data(pairs: List[str], timeframes: List[str] = None, 
                             force: bool = False) -> bool:
    """
    Prepare advanced training datasets with sophisticated feature engineering.
    
    Args:
        pairs: List of trading pairs
        timeframes: List of timeframes
        force: Whether to force data regeneration
        
    Returns:
        success: Whether the operation succeeded
    """
    if timeframes is None:
        timeframes = DEFAULT_TIMEFRAMES
    
    timeframes_arg = ",".join(timeframes)
    pairs_arg = ",".join(pairs)
    
    cmd = [
        sys.executable, "prepare_advanced_training_data.py",
        "--pairs", pairs_arg,
        "--timeframes", timeframes_arg,
        "--advanced-features",
        "--cross-asset-correlation",
        "--market-regime-detection",
        "--sentiment-analysis",
        "--feature-selection"
    ]
    
    if force:
        cmd.append("--force")
    
    success, _ = run_command(
        cmd,
        f"Preparing advanced training data for {pairs_arg}",
        capture_output=True
    )
    
    return success


def optimize_hyperparameters(pair: str, model_type: str, 
                         trials: int = 100, objective: str = "custom_metric",
                         parallel: bool = True) -> bool:
    """
    Optimize hyperparameters for a specific model type and pair.
    
    Args:
        pair: Trading pair
        model_type: Model type
        trials: Number of optimization trials
        objective: Optimization objective
        parallel: Whether to run optimization in parallel
        
    Returns:
        success: Whether the optimization succeeded
    """
    cmd = [
        sys.executable, "optimize_hyperparameters.py",
        "--pair", pair,
        "--model", model_type,
        "--trials", str(trials),
        "--objective", objective,
        "--multi-objective",
        "--time-series-split",
        "--cv-folds", "10",
        "--early-stopping"
    ]
    
    if parallel:
        cmd.extend(["--parallel", "--n-jobs", "4"])
    
    success, _ = run_command(
        cmd,
        f"Optimizing {model_type} hyperparameters for {pair}",
        capture_output=True
    )
    
    return success


def train_base_model(pair: str, model_type: str, stage: int,
                  target_accuracy: float = TARGET_ACCURACY) -> bool:
    """
    Train a base model for a specific pair and model type.
    
    Args:
        pair: Trading pair
        model_type: Model type to train
        stage: Training stage
        target_accuracy: Target accuracy
        
    Returns:
        success: Whether the training succeeded
    """
    cmd = [
        sys.executable, "train_advanced_model.py",
        "--pair", pair,
        "--model", model_type,
        "--stage", str(stage),
        "--target-accuracy", str(target_accuracy)
    ]
    
    success, _ = run_command(
        cmd,
        f"Training {model_type} model for {pair} (Stage {stage})",
        capture_output=True
    )
    
    return success


def create_ultra_ensemble(pair: str, model_types: List[str], 
                      optimization_method: str = "custom",
                      calibration_method: str = "temperature_scaling",
                      target_accuracy: float = TARGET_ACCURACY) -> bool:
    """
    Create an ultra-optimized ensemble model.
    
    Args:
        pair: Trading pair
        model_types: List of model types to include
        optimization_method: Method for optimizing ensemble weights
        calibration_method: Method for calibrating probabilities
        target_accuracy: Target accuracy
        
    Returns:
        success: Whether the ensemble creation succeeded
    """
    models_arg = ",".join(model_types)
    
    cmd = [
        sys.executable, "create_ultra_ensemble.py",
        "--pair", pair,
        "--models", models_arg,
        "--optimization-method", optimization_method,
        "--calibration-method", calibration_method,
        "--target-accuracy", str(target_accuracy),
        "--cross-validation", "10"
    ]
    
    success, _ = run_command(
        cmd,
        f"Creating ultra-optimized ensemble for {pair}",
        capture_output=True
    )
    
    return success


def run_comprehensive_backtest(pair: str, target_return: float = TARGET_RETURN) -> Tuple[bool, Dict]:
    """
    Run comprehensive backtesting for a pair.
    
    Args:
        pair: Trading pair
        target_return: Target return
        
    Returns:
        success: Whether the backtest succeeded
        results: Backtest results
    """
    cmd = [
        sys.executable, "run_comprehensive_backtest.py",
        "--pair", pair,
        "--model", "ensemble",
        "--period", "365",
        "--calculate-all-metrics",
        "--output-format", "json"
    ]
    
    success, output = run_command(
        cmd,
        f"Running comprehensive backtest for {pair}",
        capture_output=True
    )
    
    if success:
        # Parse JSON output
        try:
            # Extract JSON from output (assuming it's at the end of the output)
            json_start = output.find("{")
            if json_start >= 0:
                json_output = output[json_start:]
                results = json.loads(json_output)
                
                # Log key metrics
                total_return = results.get("total_return", 0)
                win_rate = results.get("win_rate", 0)
                accuracy = results.get("accuracy", 0)
                
                logger.info(f"Backtest results for {pair}:")
                logger.info(f"  Total Return: {total_return:.2f}x (Target: {target_return:.2f}x)")
                logger.info(f"  Win Rate: {win_rate:.4f}")
                logger.info(f"  Accuracy: {accuracy:.4f}")
                
                return True, results
            else:
                logger.error("No JSON output found in backtest results")
                return False, {}
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing backtest results: {e}")
            return False, {}
    
    return False, {}


def update_training_parameters(pair: str, config: Dict, results: Dict, 
                           stage: int, target_accuracy: float,
                           target_win_rate: float, target_return: float) -> Dict:
    """
    Update training parameters based on current results.
    
    Args:
        pair: Trading pair
        config: Current configuration
        results: Current results
        stage: Current stage
        target_accuracy: Target accuracy
        target_win_rate: Target win rate
        target_return: Target return
        
    Returns:
        updated_config: Updated configuration
    """
    logger.info(f"Updating training parameters for {pair} (Stage {stage})")
    
    # Make a copy of the config to avoid modifying the original
    updated_config = config.copy()
    
    # Get current pair settings
    pair_settings = updated_config.get("pair_specific_settings", {}).get(pair, {})
    
    # Extract current metrics
    accuracy = results.get("accuracy", 0)
    win_rate = results.get("win_rate", 0)
    total_return = results.get("total_return", 0)
    
    # Calculate gaps to targets
    accuracy_gap = target_accuracy - accuracy
    win_rate_gap = target_win_rate - win_rate
    return_gap = target_return - total_return
    
    # Update parameters based on gaps
    if accuracy_gap > 0:
        # Increase lookback window if accuracy is low
        current_lookback = pair_settings.get("lookback_window", 120)
        pair_settings["lookback_window"] = min(240, int(current_lookback * 1.2))
        
        # Adjust confidence threshold
        current_threshold = pair_settings.get("confidence_threshold", 0.65)
        pair_settings["confidence_threshold"] = min(0.90, current_threshold + 0.05)
    
    if win_rate_gap > 0:
        # Adjust risk parameters for better win rate
        current_risk = pair_settings.get("risk_percentage", 0.20)
        # Lower risk slightly to improve win rate
        pair_settings["risk_percentage"] = max(0.10, current_risk - 0.02)
    
    if return_gap > 0:
        # Increase leverage for better returns
        current_base_leverage = pair_settings.get("base_leverage", 40.0)
        current_max_leverage = pair_settings.get("max_leverage", 125.0)
        
        # Increase leverage (with caution)
        pair_settings["base_leverage"] = min(50.0, current_base_leverage + 2.0)
        pair_settings["max_leverage"] = min(125.0, current_max_leverage + 2.0)
    
    # Update target values
    pair_settings["target_accuracy"] = target_accuracy
    pair_settings["expected_win_rate"] = target_win_rate
    pair_settings["target_return"] = target_return
    
    # Update configuration
    updated_config["pair_specific_settings"][pair] = pair_settings
    
    # Log changes
    logger.info(f"Updated parameters for {pair}:")
    logger.info(f"  lookback_window: {pair_settings.get('lookback_window')}")
    logger.info(f"  confidence_threshold: {pair_settings.get('confidence_threshold')}")
    logger.info(f"  risk_percentage: {pair_settings.get('risk_percentage')}")
    logger.info(f"  base_leverage: {pair_settings.get('base_leverage')}")
    logger.info(f"  max_leverage: {pair_settings.get('max_leverage')}")
    
    # Save updated configuration for this stage
    temp_config_path = f"{OUTPUT_DIR}/stage_{stage}_{pair.replace('/', '_')}_config.json"
    try:
        with open(temp_config_path, 'w') as f:
            json.dump(updated_config, f, indent=2)
        logger.info(f"Saved updated configuration to {temp_config_path}")
    except Exception as e:
        logger.error(f"Error saving updated config: {e}")
    
    return updated_config


def train_pair(pair: str, config: Dict, args, stage: int = 1) -> Tuple[bool, Dict]:
    """
    Execute the complete training process for a single pair at a specific stage.
    
    Args:
        pair: Trading pair
        config: Configuration
        args: Command line arguments
        stage: Training stage
        
    Returns:
        success: Whether the training succeeded
        results: Training results
    """
    logger.info(f"=== Starting Stage {stage} training for {pair} ===")
    
    # Get model types to train
    model_types = config.get("training_config", {}).get("ensemble", {}).get("models", 
                                                                     ["tcn", "lstm", "attention_gru", "transformer"])
    
    # For stage 1, start with the base model types
    if stage == 1:
        model_types = [m for m in model_types if m in ["tcn", "lstm", "attention_gru", "transformer"]]
    
    # For later stages, include tree-based models
    else:
        # Ensure we have the full set of models
        if "xgboost" not in model_types:
            model_types.append("xgboost")
        if "lightgbm" not in model_types:
            model_types.append("lightgbm")
    
    # Step 1: Optimize hyperparameters (if not skipped)
    if not args.skip_hyperopt:
        # Start with fewer trials for earlier stages
        trials = 50 if stage == 1 else 100 if stage == 2 else 200
        
        for model_type in model_types:
            logger.info(f"Optimizing {model_type} model for {pair}")
            optimize_hyperparameters(pair, model_type, trials=trials, objective="custom_metric")
    
    # Step 2: Train base models
    for model_type in model_types:
        logger.info(f"Training {model_type} model for {pair}")
        train_base_model(pair, model_type, stage, args.target_accuracy)
    
    # Step 3: Create ultra-optimized ensemble
    logger.info(f"Creating ensemble model for {pair}")
    create_ultra_ensemble(
        pair, 
        model_types, 
        optimization_method="custom" if stage == 1 else "bayesian",
        calibration_method="temperature_scaling",
        target_accuracy=args.target_accuracy
    )
    
    # Step 4: Run comprehensive backtest
    logger.info(f"Running backtest for {pair}")
    success, results = run_comprehensive_backtest(pair, args.target_return)
    
    if not success:
        logger.error(f"Backtest failed for {pair}")
        return False, {}
    
    # Step 5: Check if targets are met
    accuracy = results.get("accuracy", 0)
    win_rate = results.get("win_rate", 0)
    total_return = results.get("total_return", 0)
    
    meets_accuracy = accuracy >= args.target_accuracy
    meets_win_rate = win_rate >= args.target_win_rate
    meets_return = total_return >= args.target_return
    
    meets_all_targets = meets_accuracy and meets_win_rate and meets_return
    
    if meets_all_targets:
        logger.info(f"‚úÖ {pair} meets all targets in stage {stage}!")
        logger.info(f"  Accuracy: {accuracy:.4f} (Target: {args.target_accuracy:.4f})")
        logger.info(f"  Win Rate: {win_rate:.4f} (Target: {args.target_win_rate:.4f})")
        logger.info(f"  Total Return: {total_return:.2f}x (Target: {args.target_return:.2f}x)")
    else:
        logger.info(f"‚ö†Ô∏è {pair} does not yet meet all targets in stage {stage}.")
        logger.info(f"  Accuracy: {accuracy:.4f} (Target: {args.target_accuracy:.4f}) - {'‚úÖ Met' if meets_accuracy else '‚ùå Not met'}")
        logger.info(f"  Win Rate: {win_rate:.4f} (Target: {args.target_win_rate:.4f}) - {'‚úÖ Met' if meets_win_rate else '‚ùå Not met'}")
        logger.info(f"  Total Return: {total_return:.2f}x (Target: {args.target_return:.2f}x) - {'‚úÖ Met' if meets_return else '‚ùå Not met'}")
    
    # Return results
    return meets_all_targets, results


def save_final_results(results: Dict):
    """
    Save final training results.
    
    Args:
        results: Results by pair and stage
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"{OUTPUT_DIR}/final_training_results_{timestamp}.json"
    
    try:
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        logger.info(f"Saved final results to {output_file}")
    except Exception as e:
        logger.error(f"Error saving final results: {e}")


def integrate_with_trading_system(successful_pairs: List[str]) -> bool:
    """
    Integrate successful models with the trading system.
    
    Args:
        successful_pairs: List of successfully trained pairs
        
    Returns:
        success: Whether the integration succeeded
    """
    if not successful_pairs:
        logger.warning("No successful pairs to integrate")
        return False
    
    pairs_arg = ",".join(successful_pairs)
    
    cmd = [
        sys.executable, "integrate_models.py",
        "--pairs", pairs_arg,
        "--models", "ensemble",
        "--sandbox"
    ]
    
    success, _ = run_command(
        cmd,
        f"Integrating models for {pairs_arg} with trading system",
        capture_output=True
    )
    
    return success


def update_ml_config(results: Dict) -> bool:
    """
    Update ML configuration with results.
    
    Args:
        results: Results dictionary
        
    Returns:
        success: Whether the update succeeded
    """
    ml_config_path = "config/ml_config.json"
    
    try:
        # Load existing ML config
        with open(ml_config_path, 'r') as f:
            ml_config = json.load(f)
        
        # Update with new pairs and their settings
        for pair, pair_results in results.items():
            if pair_results.get("success", False):
                # Get best stage results
                best_stage = max(pair_results["stages"].keys(), key=int)
                stage_results = pair_results["stages"][best_stage]
                
                # Add or update pair settings
                if "pairs" not in ml_config:
                    ml_config["pairs"] = {}
                
                ml_config["pairs"][pair] = {
                    "base_leverage": stage_results.get("base_leverage", 45.0),
                    "max_leverage": stage_results.get("max_leverage", 125.0),
                    "confidence_threshold": stage_results.get("confidence_threshold", 0.75),
                    "risk_percentage": stage_results.get("risk_percentage", 0.20),
                    "active": True,
                    "trained": True,
                    "ensemble": True,
                    "expected_accuracy": stage_results.get("accuracy", 0.99),
                    "expected_win_rate": stage_results.get("win_rate", 0.99),
                    "expected_return": stage_results.get("total_return", 10.0)
                }
        
        # Save updated config
        with open(ml_config_path, 'w') as f:
            json.dump(ml_config, f, indent=2)
        
        logger.info(f"Updated ML configuration in {ml_config_path}")
        return True
    
    except Exception as e:
        logger.error(f"Error updating ML config: {e}")
        return False


def main():
    """Main function."""
    # Parse command line arguments
    args = parse_arguments()
    
    # Determine pairs to train
    pairs = args.pairs.split(',') if args.pairs else NEW_COINS
    
    # Determine timeframes
    timeframes = args.timeframes.split(',') if args.timeframes else DEFAULT_TIMEFRAMES
    
    logger.info(f"Starting training pipeline for pairs: {', '.join(pairs)}")
    logger.info(f"Timeframes: {', '.join(timeframes)}")
    logger.info(f"Stages: {args.stages}")
    logger.info(f"Target metrics - Accuracy: {args.target_accuracy}, "
               f"Win Rate: {args.target_win_rate}, "
               f"Return: {args.target_return}x")
    
    # Load configuration
    config = load_config()
    if not config:
        logger.error("Failed to load configuration. Exiting.")
        return 1
    
    # Step 1: Fetch historical data
    if not args.skip_data_prep:
        logger.info("Fetching historical data")
        success = fetch_historical_data(pairs, timeframes, days=365, force=args.force)
        if not success:
            logger.error("Failed to fetch historical data. Exiting.")
            return 1
    
    # Step 2: Prepare advanced training data
    if not args.skip_data_prep:
        logger.info("Preparing advanced training data")
        success = prepare_advanced_training_data(pairs, timeframes, force=args.force)
        if not success:
            logger.error("Failed to prepare training data. Exiting.")
            return 1
    
    # Track results by pair and stage
    results = {pair: {
        "success": False,
        "stages": {}
    } for pair in pairs}
    
    # Step 3: Train each pair through multiple stages
    for pair in pairs:
        pair_config = config
        meets_targets = False
        
        for stage in range(1, args.stages + 1):
            logger.info(f"=== Starting Stage {stage}/{args.stages} for {pair} ===")
            
            # Train the pair for this stage
            meets_targets, stage_results = train_pair(pair, pair_config, args, stage)
            
            # Save the stage results
            results[pair]["stages"][str(stage)] = stage_results
            
            # If meets all targets, we're done with this pair
            if meets_targets:
                logger.info(f"üéâ {pair} achieved all targets in stage {stage}!")
                results[pair]["success"] = True
                break
            
            # Otherwise, update parameters for next stage
            if stage < args.stages:
                pair_config = update_training_parameters(
                    pair, pair_config, stage_results, 
                    stage, args.target_accuracy, args.target_win_rate, args.target_return
                )
        
        # Final status for this pair
        if results[pair]["success"]:
            logger.info(f"‚úÖ {pair} training completed successfully in {stage} stages")
        else:
            logger.info(f"‚ö†Ô∏è {pair} training completed, but did not meet all targets")
            # Mark as successful anyway if we got close
            best_stage = max(results[pair]["stages"].keys(), key=int)
            best_results = results[pair]["stages"][best_stage]
            
            accuracy = best_results.get("accuracy", 0)
            win_rate = best_results.get("win_rate", 0)
            total_return = best_results.get("total_return", 0)
            
            if (accuracy >= args.target_accuracy * 0.95 and 
                win_rate >= args.target_win_rate * 0.95 and
                total_return >= args.target_return * 0.9):
                logger.info(f"üìä {pair} achieved close to target metrics, marking as successful")
                results[pair]["success"] = True
    
    # Save final results
    save_final_results(results)
    
    # Get list of successful pairs
    successful_pairs = [pair for pair, pair_results in results.items() 
                      if pair_results.get("success", False)]
    
    # Step 4: Integrate successful models with trading system
    if successful_pairs:
        logger.info(f"Integrating successful models: {', '.join(successful_pairs)}")
        integrate_with_trading_system(successful_pairs)
        
        # Update ML configuration
        update_ml_config(results)
    else:
        logger.warning("No pairs achieved target metrics")
    
    # Final summary
    logger.info("=== Training Pipeline Complete ===")
    logger.info(f"Total pairs: {len(pairs)}")
    logger.info(f"Successful pairs: {len(successful_pairs)}/{len(pairs)}")
    
    for pair in pairs:
        status = "‚úÖ Success" if results[pair]["success"] else "‚ùå Did not meet targets"
        logger.info(f"  {pair}: {status}")
        
        # Show best metrics
        if results[pair]["stages"]:
            best_stage = max(results[pair]["stages"].keys(), key=int)
            best_results = results[pair]["stages"][best_stage]
            
            accuracy = best_results.get("accuracy", 0)
            win_rate = best_results.get("win_rate", 0)
            total_return = best_results.get("total_return", 0)
            
            logger.info(f"    Best metrics (Stage {best_stage}): "
                      f"Accuracy: {accuracy:.4f}, Win Rate: {win_rate:.4f}, "
                      f"Return: {total_return:.2f}x")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())